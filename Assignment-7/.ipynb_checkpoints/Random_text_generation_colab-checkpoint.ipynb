{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nbQcwybsM2Cv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AbFcH_3PM2Cy",
    "outputId": "c137ce5c-4c99-4e4c-b476-73ddbb077500"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "rxom1_i0NO3M",
    "outputId": "9d0e6a72-cf97-43f6-a1c0-ab8a5df5b994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1122304/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI5iKJP_M2C1"
   },
   "outputs": [],
   "source": [
    "#Loading the file location\n",
    "text = open(path_to_file, encoding ='utf').read()\n",
    "text = text[:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "XjLIuTgZM2DC",
    "outputId": "ed26e03b-4400-46c9-9a77-917a85650703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars:  65\n",
      "number of sequences: 333300\n"
     ]
    }
   ],
   "source": [
    "# Getting sorted listof char in text\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars: ', len(chars))\n",
    "\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Spitting text into sentences\n",
    "maxlen = 100\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('number of sequences:', len(sentences))\n",
    "\n",
    "# Character level One - hot Encoding\n",
    "x_train = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y_train = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x_train[i, t, char_indices[char]] = 1\n",
    "    y_train[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4SfIrW_Vk-d"
   },
   "outputs": [],
   "source": [
    "def next_batch(x, y, batch_size):\n",
    "    N = x.shape[0]\n",
    "    batch_indices = np.random.permutation(N)[:batch_size]\n",
    "    x_batch = x[batch_indices]\n",
    "    y_batch = y[batch_indices]\n",
    "    return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCEi0wEjWJFy"
   },
   "outputs": [],
   "source": [
    "# Data Dimensions\n",
    "input_dim = len(chars)       # input dimension\n",
    "seq_max_len = maxlen         # sequence maximum length\n",
    "out_dim = len(chars)         # output dimension \n",
    "\n",
    "# Hyper-Parameters\n",
    "learning_rate = 0.01    # The optimization initial learning rate\n",
    "training_steps = 1000  # Total number of training steps\n",
    "batch_size = 256        # batch size\n",
    "display_freq = 100    # Frequency of displaying the training results\n",
    "num_hidden_units = 1024   # number of hidden units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1AyAQaKsu-kY"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdGabHZEWJ4R"
   },
   "outputs": [],
   "source": [
    "# weight and bais wrappers\n",
    "def weight_variable(shape):\n",
    "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
    "    return tf.get_variable('W',\n",
    "                           dtype=tf.float64,\n",
    "                           shape=shape,\n",
    "                           initializer=initer)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0., shape=shape, dtype=tf.float64)\n",
    "    return tf.get_variable('b',\n",
    "                           dtype=tf.float64,\n",
    "                           initializer=initial)\n",
    "\n",
    "with tf.name_scope('Input'):\n",
    "    x = tf.placeholder(tf.float64, shape=[None, seq_max_len, input_dim], name='X')\n",
    "    y = tf.placeholder(tf.float64, shape=[None, out_dim], name='Y')\n",
    "    keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IBaVyuidWJ55"
   },
   "outputs": [],
   "source": [
    "def LSTM(x, num_hidden, out_dim, name, use_activation=True, keep_prob = None):\n",
    "    with tf.variable_scope(name):\n",
    "        # create weight matrix initialized randomely from N~(0, 0.01)\n",
    "        weights = weight_variable(shape=[num_hidden_units, out_dim])\n",
    "\n",
    "        # create bias vector initialized as zero\n",
    "        biases = bias_variable(shape=[out_dim])\n",
    "\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(num_hidden)\n",
    "        outputs, states = tf.nn.dynamic_rnn(cell, x, dtype=tf.float64)\n",
    "        out = tf.matmul(outputs[:, -1, :], weights) + biases\n",
    "        \n",
    "        layer = tf.nn.dropout(out, keep_prob)\n",
    "        \n",
    "        layer = tf.layers.dense(layer,units=out_dim)\n",
    "        \n",
    "        layer = tf.nn.softmax(layer)\n",
    "        \n",
    "    \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "WpxyoS4hWiOy",
    "outputId": "69eb4e90-c5e3-41bd-cfd3-9a815dc937ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0702 19:19:08.798438 140049630615424 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "logits_out = LSTM(x, num_hidden_units, out_dim=out_dim, name = 'lstm',use_activation=True, keep_prob = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G8yEooi3iWRv"
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y, logits_out))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-U5kgaZ4WJ9v",
    "outputId": "f29ebace-4dbb-438b-ed9d-070808a8456a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Loss=4.174720242098493\n"
     ]
    }
   ],
   "source": [
    "# Creating the op for initializing all variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(training_steps):\n",
    "    x_batch, y_batch = next_batch(x_train, y_train, batch_size)\n",
    "    _, batch_loss = sess.run([train_op, loss], feed_dict={x: x_batch, y: y_batch})\n",
    "    if i % display_freq == 0:\n",
    "        print('Step {}, Loss={}'.format(i, batch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mUMR1yT8WJ_6"
   },
   "outputs": [],
   "source": [
    "# Testing\n",
    "def sample(preds, temperature):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "  \n",
    "import random\n",
    "\n",
    "def generate_text(length, diversity):\n",
    "    # Get random starting text\n",
    "    start_index = 0 #random.randint(0, len(text) - maxlen - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = sess.run(tf.squeeze(sess.run(logits_out, feed_dict = {x: x_pred})))\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 938
    },
    "colab_type": "code",
    "id": "EgTp-K3g4WJo",
    "outputId": "f54cf0d7-29a7-4eb7-d58d-fbffc7495a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2  - diversity----------------------------------------\n",
      "mortal passado! the punto reverso! the\n",
      "hai!\n",
      "\n",
      "BENVOLIO:\n",
      "The what?\n",
      "\n",
      "MERCUTIO:\n",
      "The pox of such antic, lont the mesd on hout to the thaut\n",
      "The the the the the the tent or ther hand the I thou he found tho that the thow the hee the ther thhe thout a I the thound here the here the soud ne the thar the ntote hor have eand thas to erond the the the thor the the thet thes wish\n",
      "the the hore the the deann the\n",
      "******************************************************\n",
      "0.5  - diversity----------------------------------------\n",
      " winter's pale.\n",
      "The white sheet bleaching on the hedge,\n",
      "With heigh! the sweet birds, O, how they sin erares and the tole sirse an yar plenes vean ane manthes as fars hefs or anm me thor heen the e anshars oush weurke thanLnentenathes preed bne anbee thile couss theur poukeg PimeQs hin ure\n",
      "I touth ecp and me to the undes sarthe soon?\n",
      "\n",
      "EGnIM, I Gole but mane lestet sot kertheg werth aot thee thou tC\n",
      "******************************************************\n",
      "1.0  - diversity----------------------------------------\n",
      "nd, for my name of George begins with G,\n",
      "It follows in his thought that I am he.\n",
      "These, as I learn, Aciknret, aKd egoelcose gloaols\n",
      "Lourreirtbtlerlh mushs rotdentue id choudd be ondIS p!nne,\n",
      "C anrbthakrvoncsoinelf cam minimisudrer,\n",
      "Jamr, umi; me mand winat Pond weKmiir orse ad Omsh lounidaYedhrYet sy igeme dairioncoun,\n",
      "Ey Cu, god pamleH whoosh thso\n",
      "EnameTpon;jouts oanFkoag,eed rryesn'd.\n",
      "\n",
      "RUNIE\n",
      ":\n",
      "M\n",
      "******************************************************\n",
      "1.2  - diversity----------------------------------------\n",
      " house of Lancaster leave to breathe,\n",
      "It will outrun you, father, in the end.\n",
      "\n",
      "YORK:\n",
      "I took an oath tht mein, thisQ hamE 'nlpruahs hihrutly houpeneey.\n",
      "? ot.\n",
      "\n",
      "DC?E-YAPTAUD::\n",
      "jensle Mive houy I\n",
      "Rq, I mnir. \n",
      "BwoKes\n",
      "REDETTTBB:\n",
      "EittXloNm Yims-bbhenu hePcht; zEGl he!\n",
      "Goun, deivhyr EedasvasimAth, furcaD me\n",
      "dett gaicynslask; wsahs bdeaRl,,\n",
      "HasthqleuOt bsecXas umI clerret bupmeZfeenlhecl e?\n",
      "I. vev elie sei\n",
      "******************************************************\n"
     ]
    }
   ],
   "source": [
    "for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "  print(diversity,\" - diversity----------------------------------------\")\n",
    "  print(generate_text(300, diversity))\n",
    "  print('******************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSJMPcjS5MtC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Random_text_generation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
